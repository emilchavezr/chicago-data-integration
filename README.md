# Chicago Data Integration Project

This project simulates a real-world scenario where public data from different sources needs to be collected, organized, and prepared for analysis. I worked with three datasets from the City of Chicago: census data, public school information, and crime reports.

Using Python and SQLite, I built a small-scale data pipeline where:

- Raw `.csv` files were cleaned and loaded with **Pandas**
- A relational database was created from scratch using **SQLite**
- Data was queried directly from the database using **SQL** inside a **Jupyter Notebook**

---

## Tools & Libraries
- Python
- Pandas
- SQLite3
- ipython-sql (SQL magic in notebooks)
- Jupyter Notebook

---

## Project Highlights
- Created and replaced tables in a local SQLite database
- Combined structured data sources into a unified queryable environment
- Executed SQL queries to extract insights directly from the database
- Built a flexible foundation for potential dashboard integration or further analysis

---

## üìÅ Files
- `Analysis_chicago.ipynb` ‚Äì full project notebook with code and SQL queries

---

Let me know if you want to try this approach or adapt it for your own data projects.  
Always open to collaboration and feedback.

---

### üí° Personal Note:
This is part of my learning journey toward becoming a well-rounded data analyst with a strong foundation in both code and data infrastructure.
